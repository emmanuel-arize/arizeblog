---
layout: python-post
title: Dropout Regularization
category: machine-learning-python
author: Arize Emmanuel
editor_options:
  markdown:
    wrap: 72
---

In this article, we will learn about , what it is, how it works and  we will implement it sampling using Python


The term <b>"dropout"</b> refers to dropping out units in a neural network. It is a technique for addressing overfitting. It consists of randomly dropping out some fraction of the nodes (setting fraction of the units to zero (injecting noise)) in each layer before calculating subsequent layer during training and has become a standard technique for training neural networks. When dropout is applied, during training its zeros out some fraction of the nodes with probability p in each layer before calculating the subsequent layer and the resulting network can be viewed as a subset of the original network. Because the fraction of the nodes that are drop out are chosen randomly on every pass, the representations in each layer can't depend on the exact values taken by nodes in the previous layer.

<b> Dropout rate</b> is the fraction of the nodes in a layer that are zeroed out and itâ€™s usually set between 0 and 1
